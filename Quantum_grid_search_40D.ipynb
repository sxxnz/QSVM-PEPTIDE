{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane import ApproxTimeEvolution\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import random\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load and label datasets\n",
    "def load_data(file_num):\n",
    "    # File paths\n",
    "    train_neg_path = f'./data/Hemo40D/data{file_num}/train/neg.fa_encod.csv'\n",
    "    train_pos_path = f'./data/Hemo40D/data{file_num}/train/pos.fa_encod.csv'\n",
    "    test_neg_path = f'./data/Hemo40D/data{file_num}/test/neg.fa_encod.csv'\n",
    "    test_pos_path = f'./data/Hemo40D/data{file_num}/test/pos.fa_encod.csv'\n",
    "    \n",
    "    # Load the CSV files\n",
    "    train_neg = pd.read_csv(train_neg_path)\n",
    "    train_pos = pd.read_csv(train_pos_path)\n",
    "    test_neg = pd.read_csv(test_neg_path)\n",
    "    test_pos = pd.read_csv(test_pos_path)\n",
    "    \n",
    "    # Insert labels (0 for negative, 1 for positive)\n",
    "    train_neg.insert(0, 'Label', 0)\n",
    "    train_pos.insert(0, 'Label', 1)\n",
    "    test_neg.insert(0, 'Label', 0)\n",
    "    test_pos.insert(0, 'Label', 1)\n",
    "\n",
    "    frames_trian = [train_neg,train_pos]\n",
    "    frames_test  = [test_neg,test_pos]\n",
    "    train_df     = pd.concat(frames_trian)\n",
    "    test_df      = pd.concat(frames_test)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def pre_process(file_num):\n",
    "    train_df, test_df = load_data(file_num)\n",
    "    column_names = train_df.columns[3:].tolist()\n",
    "\n",
    "    scaler        = StandardScaler()  # mean 0 and std 1\n",
    "    undersampleer = RandomUnderSampler(random_state=42)\n",
    "\n",
    "    train_df[column_names] = scaler.fit_transform(train_df[column_names])\n",
    "    test_df[column_names]  = scaler.transform(test_df[column_names])\n",
    "    \n",
    "    x      = train_df[column_names].to_numpy()\n",
    "    y      = train_df['Label'].to_numpy()\n",
    "    x_test = test_df[column_names].to_numpy()\n",
    "    y_test = test_df['Label'].to_numpy()\n",
    "\n",
    "    X,y = undersampleer.fit_resample(x, y)\n",
    "    return X,y,x_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hemo1,y_hemo1,x_hemo1_test,y_hemo1_test = pre_process(1)\n",
    "x_hemo2,y_hemo2,x_hemo2_test,y_hemo2_test = pre_process(2)\n",
    "x_hemo3,y_hemo3,x_hemo3_test,y_hemo3_test = pre_process(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create one random Pauli String \n",
    "def one_operator(num_qubits):\n",
    "    ops_list = [qml.PauliX, qml.PauliY, qml.PauliZ,qml.Identity] # Pauli matrices\n",
    "    return qml.operation.Tensor(*(random.choice(ops_list)(i) for i in range(num_qubits)))\n",
    "\n",
    "# Function to create multiple random Pauli String\n",
    "def hamiltonian_operators(num_qubits, num_ops,num_samples=1):\n",
    "    ops_all = []\n",
    "    for _ in range(num_samples):\n",
    "        ops = []\n",
    "        for _ in range(num_ops):\n",
    "            op = one_operator(num_qubits)\n",
    "            ops.append(op)\n",
    "        ops_all.append(ops)\n",
    "    return ops_all\n",
    "\n",
    "\n",
    "# Kernel matrix \n",
    "def kernel_matrix(A,B):\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    \n",
    "    return np.absolute(np.matmul(np.conjugate(A),B.T)**2)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "num_qubits = [6,8,10,12,14]    # number of qubits\n",
    "L          = 40                # number of operators = number of descriptors\n",
    "n_sample   = 30                # number of samples for each number of qubits\n",
    "ops_dict   = {}\n",
    "\n",
    "for n in num_qubits:\n",
    "    ops_dict[f'{n}_qubits'] = hamiltonian_operators(num_qubits=n,num_ops=L,num_samples=n_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train quantum kernels with StratifiedKFold\n",
    "# for different number of qubits, time, trotter steps and Pauli Strings\n",
    "def train(n_qubits,time,step,X,y,n_ops=3):\n",
    "    print('{:5s} | {:5s} | {:3s} | {:3s} | {:7s}  | {:7s} | {:7s}'\"\"\n",
    "            .format('CV','Num Qubits','Time','Step','Ops Index','Train_Acc','Val_acc'))\n",
    "    \n",
    "    Column_name = ['Num Qubits','Time','Step','Ops Index','Training Accuracy','Validation Accuracy']\n",
    "    kf = StratifiedKFold(n_splits=5, random_state=42, shuffle= True)\n",
    "\n",
    "    results = []\n",
    "    for n in n_qubits:\n",
    "        dev = qml.device(\"lightning.qubit\", wires=n)        \n",
    "        for t in time:\n",
    "            for s in step:\n",
    "                for o in range(n_ops): \n",
    "                \n",
    "                    ops = ops_dict[str(n)+'_qubits'][o] \n",
    "\n",
    "                    @qml.qnode(dev, interface=\"autograd\")\n",
    "                    def kernel(ops, x,time=1,steps=1):   \n",
    "\n",
    "                        hamiltonian = qml.Hamiltonian(x, ops)\n",
    "                        ApproxTimeEvolution(hamiltonian, time, steps)\n",
    "\n",
    "                        return qml.state()\n",
    "                    \n",
    "                    for i,(train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "                        X_train, X_val = X[train_index], X[val_index]\n",
    "                        y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "                        q_state    = [ kernel(ops,x,t,s) for x in X_train] # training states\n",
    "                        val_state  = [ kernel(ops,x,t,s) for x in X_val] # validation states\n",
    "\n",
    "                        k_matrix   = kernel_matrix(q_state,q_state) # Compute kernel matrix with training set\n",
    "                        svm        = SVC(kernel='precomputed').fit(k_matrix, y_train)  # Fit \n",
    "                        train_pred = svm.predict(k_matrix)\n",
    "                        train_acc  = accuracy_score(y_train,train_pred)\n",
    "\n",
    "                        val_matrix = kernel_matrix(q_state,val_state) # Compute kernel matrix with validation set\n",
    "                        y_pred     = svm.predict(val_matrix.T) # Prediction\n",
    "                        val_acc    = accuracy_score(y_val,y_pred) # Validation accuracy\n",
    "                        result = [n,t,s,o,train_acc,val_acc]\n",
    "                        results.append(result)\n",
    "\n",
    "                        print(\"{:>4}/5| {:>11}| {:>4} | {:>4} | {:>11d}| {:>10f}| {:7f}\"\n",
    "                                \"\".format(i+1,n,t,s,o,train_acc,val_acc))\n",
    "\n",
    "\n",
    "    result_df = pd.DataFrame(results,columns=Column_name)\n",
    "\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute test accuracy on quantum kernels\n",
    "def testing(num_qubits,time,step,ops_index,xdata,ydata,x_test,y_test):\n",
    "\n",
    "    n_qubits = num_qubits\n",
    "    dev_kernel = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "    @qml.qnode(dev_kernel, interface=\"autograd\")\n",
    "    def kernel(x,ops,time=1,steps=1):   \n",
    "        \n",
    "        hamiltonian_1 = qml.Hamiltonian(x, ops)\n",
    "        ApproxTimeEvolution(hamiltonian_1, time, steps)\n",
    "        return qml.state()\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "\n",
    "    ops_n8 = ops_dict[str(n_qubits)+'_qubits'][ops_index]\n",
    "\n",
    "    q_state    = [ kernel(x,ops_n8,time,step) for x in xdata] # training states\n",
    "    test_state = [ kernel(x,ops_n8,time,step) for x in x_test] # testing states\n",
    "\n",
    "    k_matrix   = kernel_matrix(q_state,q_state) # Compute kernel matrix with training set\n",
    "    svm        = SVC(kernel='precomputed').fit(k_matrix, ydata)  # Fit \n",
    "\n",
    "    test_matrix = kernel_matrix(q_state,test_state)\n",
    "    test_pred   = svm.predict(test_matrix.T)\n",
    "    test_score  = svm.decision_function(test_matrix.T)\n",
    "\n",
    "    test_acc    = accuracy_score(y_test,test_pred)\n",
    "\n",
    "    precision = precision_score(y_test, test_pred,pos_label=1)\n",
    "    recall    = recall_score(y_test, test_pred,pos_label=1)\n",
    "    f1_       = f1_score(y_test, test_pred,pos_label=1)\n",
    "    roc_auc_  = roc_auc_score(y_test, test_score)\n",
    "\n",
    "    print(f\"Testing accuracy: {test_acc:.5f}\")\n",
    "    print(f\"Precision: {precision:.5f}\")\n",
    "    print(f\"Recall: {recall:.5f}\")\n",
    "    print(f\"F1: {f1_:.5f}\")\n",
    "    print(f\"ROC AUC: {roc_auc_:.5f}\")\n",
    "\n",
    "\n",
    "    return [test_acc,precision,recall,f1_,roc_auc_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_avg(df_TrainVal,df_test):\n",
    "    df_TrainVal_mean = df_TrainVal.groupby(['Num Qubits', 'Time','Step','Ops Index']).agg(\n",
    "                                            Average_Train_Accuracy=('Training Accuracy', 'mean'),\n",
    "                                            Average_Val_Accuracy=('Validation Accuracy', 'mean')).reset_index()\n",
    "    df_TrainVal_mean['Test_Accuracy'] =  df_test\n",
    "\n",
    "    return df_TrainVal_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "- First grid search with wider range of time steps.\n",
    "- Second grid search with finer area where the gap between train and validation accuracy is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[6]\n",
    "time = [0.1,0.3,0.5,0.7,0.9,1]\n",
    "step = [1,5,10,20]\n",
    "hemo1_wide_range = train(n,time,step,x_hemo1,y_hemo1)\n",
    "hemo1_wide_range.to_csv('./result/hemo1_wide_range.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[6]\n",
    "time = [0.12,0.15,0.17,0.2,0.22,0.25,0.27]\n",
    "step=[1,5,10,20]\n",
    "hemo1_fine_search = train(n,time,step,x_hemo1,y_hemo1)\n",
    "hemo1_fine_search.to_csv('./result/hemo1_fine_search.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[6]\n",
    "time = [0.1,0.3,0.5,0.7,0.9,1]\n",
    "step = [1,5,10]\n",
    "hemo2_wide_range = train(n,time,step,x_hemo2,y_hemo2)\n",
    "hemo2_wide_range.to_csv('./result/hemo2_wide_range.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[6]\n",
    "time = [0.12,0.15,0.17,0.2,0.22,0.25,0.27]\n",
    "step=[1,5,10,20]\n",
    "hemo2_fine_search = train(n,time,step,x_hemo2,y_hemo2)\n",
    "hemo2_fine_search.to_csv('./result/hemo2_fine_search.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[6]\n",
    "time = [0.1,0.3,0.5,0.7,0.9,1]\n",
    "step = [1,5,10,20]\n",
    "hemo3_wide_range = train(n,time,step,x_hemo3,y_hemo3)\n",
    "hemo3_wide_range.to_csv('./result/hemo3_wide_range.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=[6]\n",
    "time = [0.12,0.15,0.17,0.2,0.22,0.25,0.27]\n",
    "step=[1,5,10,20]\n",
    "hemo3_fine_search = train(n,time,step,x_hemo3,y_hemo3)\n",
    "hemo3_fine_search.to_csv('./result/hemo3_fine_search.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "#### Train, validation and testing ACC on 30 sets of random Pauli Strings with best $t$ and $s$ identified from grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [6]\n",
    "time = [0.3]\n",
    "step = [10]\n",
    "\n",
    "hemo1_30sets = train(n,time,step,x_hemo1,y_hemo1,n_ops=30)\n",
    "hemo1_30sets_test = [testing(n,time,step,i,x_hemo1,y_hemo1,x_hemo1_test,y_hemo1_test)[0] for i in range(30)] # Collect only test accuracy\n",
    "\n",
    "hemo1_30sets_mean  = df_avg(hemo1_30sets,hemo1_30sets_test)\n",
    "hemo1_30sets_mean.to_csv('./result/hemo1_30sets_mean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [6]\n",
    "time = [0.15]\n",
    "step = [10]\n",
    "\n",
    "hemo2_30sets = train(n,time,step,x_hemo2,y_hemo2,n_ops=30)\n",
    "hemo2_30sets_test = [testing(n,time,step,i,x_hemo2,y_hemo2,x_hemo2_test,y_hemo2_test)[0] for i in range(30)]\n",
    "\n",
    "hemo2_30sets_mean  = df_avg(hemo2_30sets,hemo2_30sets_test)\n",
    "hemo2_30sets_mean.to_csv('./result/hemo2_30sets.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [6]\n",
    "time = [0.15]\n",
    "step = [10]\n",
    "hemo3_30sets = train(n,time,step,x_hemo3,y_hemo3,n_ops=30)\n",
    "hemo3_30sets_test = [testing(n,time,step,i,x_hemo3,y_hemo3,x_hemo3_test,y_hemo3_test)[0] for i in range(30)]\n",
    "\n",
    "hemo3_30sets_mean  = df_avg(hemo3_30sets,hemo3_30sets_test)\n",
    "hemo3_30sets_mean.to_csv('./result/hemo3_30sets.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
